{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import time\n",
    "import edist.ted as ted\n",
    "import joblib\n",
    "\n",
    "# try to load data\n",
    "import os\n",
    "\n",
    "import hyperelastic_laws as hyperelastic\n",
    "import torch\n",
    "import sympy \n",
    "from sympy import Pow, MatrixSymbol, Trace, log, MatMul\n",
    "import numpy as np\n",
    "import symengine as se\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "\n",
    "import tree\n",
    "\n",
    "import cma\n",
    "\n",
    "import recursive_tree_grammar_auto_encoder as rtg_ae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 3125*6\n",
    "N = 32\n",
    "N_test = 100\n",
    "\n",
    "learning_rate = 1E-3\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 128\n",
    "dim_vae  = 8\n",
    "num_params = 0\n",
    "model = rtg_ae.TreeGrammarAutoEncoder(hyperelastic.grammar, dim = dim, dim_vae = dim_vae)\n",
    "for key in model.state_dict():\n",
    "    num_params += model.state_dict()[key].numel()\n",
    "print('The model contains %d parameters' % (num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_algebraic_string(nodes, adj, i = 0):\n",
    "    if list(',') in list(map(str.split, nodes[i])):\n",
    "        return list(map(str.split, str(nodes[i])))[0][0] + '.'+ list(map(str.split, str(nodes[i])))[2][0]\n",
    "    if nodes[i] == '+' or nodes[i] == '*' or nodes[i] == '-'  or nodes[i] == '/':\n",
    "        return to_algebraic_string(nodes, adj, adj[i][0]) + ' ' + nodes[i] + ' ' + to_algebraic_string(nodes, adj, adj[i][1])\n",
    "    if nodes[i] == 'log' or nodes[i] == 'exp':\n",
    "        return nodes[i] + '(' + to_algebraic_string(nodes, adj, adj[i][0]) + ')'\n",
    "    if nodes[i] == 'pow':\n",
    "        return '(' + to_algebraic_string(nodes, adj, adj[i][0]) + ')' + '**' + to_algebraic_string(nodes, adj, adj[i][1])\n",
    "    if nodes[i] == '(J-1)':\n",
    "        return '(' + nodes[i] + ')' \n",
    "    if nodes[i] == '(I1-3)':\n",
    "        return '(' + 'I1-3' + ')' \n",
    "    if nodes[i] == '(I2-3)':\n",
    "        return '(' + 'I2-3' + ')'\n",
    "    else:\n",
    "        return nodes[i]\n",
    "\n",
    "def evaluate_se(nodes, adj, I1_tilde, I2_tilde, J_tilde):\n",
    "    J, I1, I2 = se.symbols(\"J I1 I2\")\n",
    "    sympy_expression = se.sympify(to_algebraic_string(nodes,adj))\n",
    "    y_all = np.zeros_like(I1_tilde)\n",
    "    for i in range(0, I1_tilde.shape[0]):\n",
    "        y_all[i] = np.array(sympy_expression.subs({J:se.Pow(se.sqrt(J_tilde[i]),2), I1:se.Pow(se.sqrt(I1_tilde[i]),2), I2:se.Pow(se.sqrt(I2_tilde[i]),2)}).evalf(16)).astype(np.float128)\n",
    "    return y_all\n",
    "\n",
    "\n",
    "def compute_invariants():\n",
    "    F11, F12, F21, F22 = se.symbols(\"F11 F12 F21 F22\")\n",
    "    F = sympy.MutableDenseMatrix([[F11, F12, 0],[F21, F22, 0],[0,0,1]])\n",
    "    J  = sympy.Pow(sympy.Determinant(F.T*F),0.5)\n",
    "    I1 = sympy.Pow(J,-2/3)*sympy.Trace(F.T*F)\n",
    "    I2 = sympy.Pow(J,-4/3)*(0.5*(sympy.Pow(sympy.Trace(sympy.MatMul(F.T,F)),2) - sympy.Trace(sympy.MatPow(sympy.MatMul(F.T,F),2))))\n",
    "    return sympy.simplify(J), sympy.simplify(I1), sympy.simplify(I2), F11, F12, F21, F22\n",
    "\n",
    "\n",
    "Ji, I1i, I2i, F11i, F12i, F21i, F22i = compute_invariants()\n",
    "def evaluate_se_mb_test(nodes, adj, F11_v, F12_v, F21_v, F22_v):\n",
    "    sympy_expression = se.sympify(to_algebraic_string(nodes,adj))\n",
    "    J, I1, I2 = se.symbols(\"J I1 I2\")\n",
    "    sympy_expression = sympy_expression.subs({J:Ji, I1:I1i, I2:I2i})\n",
    "    y_all = np.zeros_like(F11_v)\n",
    "    for i in range(0, F11_v.shape[0]):\n",
    "        y_all[i] = np.array(sympy_expression.subs({F11i:F11_v[i], F12i:F12_v[i], F21i:F21_v[i], F22i:F22_v[i]}).evalf(16)).astype(np.float128)\n",
    "    return y_all\n",
    "\n",
    "def objective_function_supervised(nodes, adj, I1_tilde, I2_tilde, J_tilde, y):\n",
    "    y_pred = evaluate_se(nodes, adj, I1_tilde, I2_tilde, J_tilde)\n",
    "    return np.sqrt(np.mean((y - y_pred) ** 2 ))\n",
    "\n",
    "\n",
    "def evaluate_se_mb(nodes, adj, F11, F12, F21, F22, num_nodes_per_element, numNodes,\\\n",
    "                 voigt_map, gradNa, qpWeights, connectivity, dirichlet_nodes, \\\n",
    "                 reactions, dim=2):\n",
    "\n",
    "    W = se.sympify(to_algebraic_string(nodes,adj))\n",
    "    J, I1, I2 = se.symbols(\"J I1 I2\")\n",
    "    # dWdJ = se.diff(W,J) \n",
    "    # Wc = dWdJ*(J-1)\n",
    "    W = W.subs({J:Ji, I1:I1i, I2:I2i})\n",
    "    F11_0 = 1.\n",
    "    F12_0 = 0\n",
    "    F21_0 = 0\n",
    "    F22_0 = 1\n",
    "\n",
    "    # Get gradients of W w.r.t F (compute)\n",
    "    dW_NN_dF11 = se.diff(W,F11i)\n",
    "    dW_NN_dF12 = se.diff(W,F12i)\n",
    "    dW_NN_dF21 = se.diff(W,F21i)\n",
    "    dW_NN_dF22 = se.diff(W,F22i)\n",
    "\n",
    "    P11 = np.zeros((F11.shape[0],))\n",
    "    P21 = np.zeros((F11.shape[0],))\n",
    "    P12 = np.zeros((F11.shape[0],))\n",
    "    P22 = np.zeros((F11.shape[0],))\n",
    "\n",
    "    P11_0 = np.zeros((F11.shape[0],))\n",
    "    P21_0 = np.zeros((F11.shape[0],))\n",
    "    P12_0 = np.zeros((F11.shape[0],))\n",
    "    P22_0 = np.zeros((F11.shape[0],))\n",
    "\n",
    "    # Sc  = np.array(Wc.subs({F11i:1, F12i:0, F21i:0, F22i:1}).evalf(16)).astype(np.float128)\n",
    "    # W0  =  np.array(W.subs({F11i:1, F12i:0, F21i:0, F22i:1}).evalf(16)).astype(np.float128)\n",
    "    # print(W0, \"W0\")\n",
    "    # print(Sc, \"Sc\")\n",
    "    # print( np.nan_to_num(W0, neginf=10), \"W0 not -inf\")\n",
    "    # print( np.nan_to_num(Sc, neginf=10), \"Sc not -inf\")\n",
    "\n",
    "    for i in range(0, F11.shape[0]):\n",
    "        P11[i] = np.array(dW_NN_dF11.subs({F11i:F11[i], F12i:F12[i], F21i:F21[i], F22i:F22[i]}).evalf(16)).astype(np.float128)\n",
    "        P12[i] = np.array(dW_NN_dF12.subs({F11i:F11[i], F12i:F12[i], F21i:F21[i], F22i:F22[i]}).evalf(16)).astype(np.float128)\n",
    "        P21[i] = np.array(dW_NN_dF21.subs({F11i:F11[i], F12i:F12[i], F21i:F21[i], F22i:F22[i]}).evalf(16)).astype(np.float128)\n",
    "        P22[i] = np.array(dW_NN_dF22.subs({F11i:F11[i], F12i:F12[i], F21i:F21[i], F22i:F22[i]}).evalf(16)).astype(np.float128)\n",
    "\n",
    "        P11_0[i] = np.array(dW_NN_dF11.subs({F11i:F11_0, F12i:F12_0, F21i:F21_0, F22i:F22_0}).evalf(16)).astype(np.float128)\n",
    "        P12_0[i] = np.array(dW_NN_dF12.subs({F11i:F11_0, F12i:F12_0, F21i:F21_0, F22i:F22_0}).evalf(16)).astype(np.float128)\n",
    "        P21_0[i] = np.array(dW_NN_dF21.subs({F11i:F11_0, F12i:F12_0, F21i:F21_0, F22i:F22_0}).evalf(16)).astype(np.float128)\n",
    "        P22_0[i] = np.array(dW_NN_dF22.subs({F11i:F11_0, F12i:F12_0, F21i:F21_0, F22i:F22_0}).evalf(16)).astype(np.float128)\n",
    "\n",
    "    # Assemble First Piola-Kirchhoff stress components\n",
    "    P_N = torch.from_numpy(np.concatenate((P11[:,None],P12[:,None],P21[:,None], P22[:,None]),axis=1)).double()\n",
    "\n",
    "    # # Get gradients of W_NN_0 w.r.t F\n",
    "    P_0 = torch.from_numpy(np.concatenate((P11_0[:,None],P12_0[:,None],P21_0[:,None], P22_0[:,None]),axis=1)).double()\n",
    "\n",
    "    P_cor = torch.zeros_like(P_0)\n",
    "\n",
    "    # # Compute stress correction components according to Ansatz\n",
    "    P_cor[:,0:1] = torch.from_numpy(F11[:,None])*-P_0[:,0:1] + torch.from_numpy(F12[:,None])*-P_0[:,2:3]\n",
    "    P_cor[:,1:2] = torch.from_numpy(F11[:,None])*-P_0[:,1:2] + torch.from_numpy(F12[:,None])*-P_0[:,3:4]\n",
    "    P_cor[:,2:3] = torch.from_numpy(F21[:,None])*-P_0[:,0:1] + torch.from_numpy(F22[:,None])*-P_0[:,2:3]\n",
    "    P_cor[:,3:4] = torch.from_numpy(F21[:,None])*-P_0[:,1:2] + torch.from_numpy(F22[:,None])*-P_0[:,3:4]\n",
    "\n",
    "    # # Compute final stress (NN + correction)\n",
    "    P = P_N + 100*P_cor\n",
    "\n",
    "    # compute internal forces on nodes\n",
    "    f_int_nodes = torch.zeros(numNodes,dim).double()\n",
    "    for a in range(num_nodes_per_element):\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                force = P[:,voigt_map[i][j]].double() * gradNa[a,:,j].double() * qpWeights.double()\n",
    "                f_int_nodes[:,i].index_add_(0, connectivity[a],force.double())\n",
    "\n",
    "    # clone f_int_nodes\n",
    "    f_int_nodes_clone = f_int_nodes.clone()\n",
    "    # set force on Dirichlet BC nodes to zero\n",
    "    f_int_nodes_clone[dirichlet_nodes] = 0.\n",
    "    # loss for force equillibrium\n",
    "    eqb_loss = torch.sum(f_int_nodes_clone**2).double()\n",
    "\n",
    "    reaction_loss = torch.tensor([0.])\n",
    "    for reaction in reactions:\n",
    "        reaction_loss += (torch.sum(f_int_nodes[reaction.dofs]).double() - reaction.force.astype(np.float128))**2\n",
    "    loss = eqb_loss.detach().numpy().astype(np.float128) + reaction_loss.detach().numpy().astype(np.float128) \n",
    "\n",
    "    return loss[0].astype(np.float128)\n",
    "\n",
    "def objective_function_unsupervised(nodes, adj, F11, F12, F21, F22, y,  num_nodes_per_element, numNodes,\\\n",
    "                 voigt_map, gradNa, qpWeights, connectivity, dirichlet_nodes, \\\n",
    "                 reactions):\n",
    "    # y_pred = evaluate_se_mb(nodes, adj, F11, F12, F21, F22)\n",
    "    loss = evaluate_se_mb(nodes, adj, F11, F12, F21, F22, num_nodes_per_element, numNodes,\\\n",
    "                 voigt_map, gradNa, qpWeights, connectivity, dirichlet_nodes, \\\n",
    "                 reactions)\n",
    "    # print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Neo_Hookean(I1, I2, J):\n",
    "    return 0.5*(I1 - 3) + 1.5*(J - 1)**2\n",
    "\n",
    "def Isihara(I1, I2, J):\n",
    "    return 0.5*(I1 - 3) + (I2 - 3) + (I1 - 3)**2 + 1.5*(J-1)**2\n",
    "\n",
    "def Haines_Wilson(I1, I2, J):\n",
    "    return 0.5*(I1 - 3) + (I2 - 3) + 0.7*(I1 - 3)*(I2 - 3) + 0.2*(I1 - 3)**3 + 1.5*(J-1)**2\n",
    "\n",
    "def Gent_Thomas(I1, I2, J):\n",
    "    return 0.5*(I1 - 3) + np.log(I2/3) + 1.5*(J-1)**2\n",
    "\n",
    "def Ogden(I1, I2, J):\n",
    "        kappa_ogden = 1.5\n",
    "        mu_ogden = 0.65\n",
    "        alpha_ogden = 0.65\n",
    "        I1_tilde = I1 + 0.0000001\n",
    "        I1t_0 = np.array([3]) + 0.0000001\n",
    "        J_0 = np.array([1]) + 0.0000001\n",
    "        W_offset = kappa_ogden*(J_0-1)**2 + 1/alpha_ogden * 2. * (0.5**alpha_ogden*(I1t_0  +  np.sqrt(  (I1t_0-1/(J_0**(2./3.)))**2 - 4*J_0**(2./3.)) - 1/(J_0**(2./3.)) )**alpha_ogden+( 0.5*I1t_0 - 0.5*np.sqrt(  (I1t_0-1/(J_0**(2./3.)))**2 - 4*J_0**(2./3.))  - 0.5/(J_0**(2./3.)) )**alpha_ogden + J_0**(-alpha_ogden*2./3.) ) * mu_ogden\n",
    "        W_truth = kappa_ogden*(J-1)**2 + 1/alpha_ogden * 2. * (0.5**alpha_ogden*(I1_tilde  +  np.sqrt(  (I1_tilde-1/(J**(2./3.)))**2 - 4*J**(2./3.)) - 1/(J**(2./3.)) )**alpha_ogden+( 0.5*I1_tilde - 0.5*np.sqrt(  (I1_tilde-1/(J**(2./3.)))**2 - 4*J**(2./3.))  - 0.5/(J**(2./3.)) )**alpha_ogden + J**(-alpha_ogden*2./3.) ) * mu_ogden - W_offset\n",
    "        return W_truth\n",
    "\n",
    "def decoding_functions(h):\n",
    "    nodes, adj, _ = model.decode(torch.tensor(h, dtype=torch.float), max_size = 2*11)\n",
    "    return nodes, adj\n",
    "\n",
    "\n",
    "# model_name = 'Neo-Hookean'\n",
    "model_name = 'Isihara'\n",
    "# model_name = 'Haines-Wilson'\n",
    "# model_name = 'Gent-Thomas'\n",
    "# model_name = 'Ogden'\n",
    "\n",
    "invalid_const = 1000.\n",
    "noiseLevel = 'noise1e4'\n",
    "\n",
    "if model_name == \"Neo-Hookean\":\n",
    "    save_file  = 'Data/' + 'NeoHookean30_' + noiseLevel\n",
    "    d30 = np.load(save_file +'.npz',allow_pickle=True)\n",
    "    f = Neo_Hookean\n",
    "\n",
    "elif model_name == \"Isihara\":\n",
    "    save_file      = 'Data/' + 'Isihara30_' + noiseLevel\n",
    "    d30 = np.load(save_file +'.npz',allow_pickle=True)\n",
    "    f = Isihara\n",
    "\n",
    "elif model_name == \"Haines-Wilson\":\n",
    "    save_file = 'Data/' + 'HainesWilson30_' + noiseLevel\n",
    "    d30 = np.load(save_file +'.npz',allow_pickle=True)\n",
    "    f = Haines_Wilson\n",
    "\n",
    "elif model_name == \"Gent-Thomas\":\n",
    "    save_file  = 'Data/' + 'GentThomas30_' + noiseLevel\n",
    "    d30 = np.load(save_file +'.npz',allow_pickle=True)\n",
    "    f = Gent_Thomas\n",
    "\n",
    "elif model_name == \"Ogden\":\n",
    "    save_file  = 'Data/' + 'Ogden30_' + noiseLevel\n",
    "    d30 = np.load(save_file +'.npz',allow_pickle=True)\n",
    "    f = Ogden\n",
    "print(model_name)\n",
    "print(save_file)\n",
    "J   = d30['J'][:,0]\n",
    "I1  = d30['I1'][:,0]\n",
    "I2  = d30['I2'][:,0]\n",
    "\n",
    "I1 = J**(-2/3)*I1\n",
    "I2 = J**(-4/3)*I2\n",
    "y = f(I1, I2, J)\n",
    "\n",
    "F11  = d30['F'][:,0]\n",
    "F12  = d30['F'][:,1]\n",
    "F21  = d30['F'][:,2]\n",
    "F22  = d30['F'][:,3]\n",
    "num_nodes_per_element = d30['numNodesPerElement']\n",
    "numNodes  = d30['numNodes'] \n",
    "voigt_map = torch.from_numpy(d30['voigtMap'])\n",
    "gradNa0= d30['gradNa0']\n",
    "gradNa1= d30['gradNa1']\n",
    "gradNa2= d30['gradNa2']\n",
    "gradNa = torch.from_numpy(np.concatenate((gradNa0[None,...],gradNa1[None,...],gradNa2[None,...]), axis=0))\n",
    "qpWeights= torch.from_numpy(d30['qpWeights'])\n",
    "connectivity0= d30['connectivity0']\n",
    "connectivity1= d30['connectivity1']\n",
    "connectivity2= d30['connectivity2']\n",
    "connectivity = torch.from_numpy(np.concatenate((connectivity0[None,...],connectivity1[None,...],connectivity2[None,...]), axis=0))\n",
    "dirichlet_nodes= torch.from_numpy(d30['dirichlet_nodes'])\n",
    "reactions=d30['reactions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('results/saved_model_hyperelastic.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fun(h):\n",
    "    try:\n",
    "        nodes, adj = decoding_functions(h)\n",
    "    # return objective_function(nodes, adj, I1, I2,J, y)\n",
    "        return objective_function_unsupervised(nodes, adj, F11, F12, F21, F22, y, num_nodes_per_element, numNodes,\\\n",
    "                    voigt_map, gradNa, qpWeights, connectivity, dirichlet_nodes, \\\n",
    "                    reactions)\n",
    "    except Exception as ex:\n",
    "        return invalid_const\n",
    "\n",
    "for i in range(0, 50):\n",
    "    text_file = open(model_name +\"_\" + noiseLevel +\"_\" + \"Flaschel\" + \"_%d\"%i + \".txt\", \"w\")\n",
    "    mu    = np.zeros(dim_vae)\n",
    "    es = cma.CMAEvolutionStrategy(mu, 0.1, {'popsize' : 100, 'ftarget': 1e-4,'verbose':1, 'maxiter' : 15})\n",
    "    es.optimize(objective_fun)\n",
    "    h_opt = es.best.__dict__['x']\n",
    "    nodes, adj = decoding_functions(h_opt)\n",
    "    # f_opt =objective_function(nodes, adj, I1, I2, J, y)\n",
    "    f_opt =objective_function_unsupervised(nodes, adj, F11, F12, F21, F22, y,  num_nodes_per_element, numNodes,\\\n",
    "                 voigt_map, gradNa, qpWeights, connectivity, dirichlet_nodes, \\\n",
    "                 reactions)\n",
    "    W = se.sympify(to_algebraic_string(nodes,adj))\n",
    "    W_init = W\n",
    "    J, I1, I2 = se.symbols(\"J I1 I2\")\n",
    "    potential_correction = sympy.simplify(W.subs({J:1, I1:3, I2:3})).evalf(16) \n",
    "    corrected_expression = W_init - potential_correction\n",
    "    print('CMA-ES found the following optimal tree: %s with evaluation %g \\n' % (corrected_expression, f_opt))\n",
    "    text_file.write('CMA-ES found the following optimal tree: %s with evaluation %g \\n' % (corrected_expression, f_opt))\n",
    "    text_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
